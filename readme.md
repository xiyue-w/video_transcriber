```{=html}
<p align="center">
```
`<img src="https://img.shields.io/badge/Python-3.11-blue.svg" />`{=html}
`<img src="https://img.shields.io/badge/Gradio-4.x-orange.svg" />`{=html}
`<img src="https://img.shields.io/badge/Whisper-Transcription-green" />`{=html}
`<img src="https://img.shields.io/badge/License-MIT-green" />`{=html}
`<img src="https://img.shields.io/github/last-commit/yourusername/video-transcriber" />`{=html}
```{=html}
</p>
```
```{=html}
<h1 align="center">
```
ğŸ¥ Video Transcriber & Annotation Tool
```{=html}
</h1>
```
```{=html}
<p align="center">
```
A Gradio-based Whisper transcription and qualitative coding interface
with GPT-assisted labeling.
```{=html}
</p>
```

------------------------------------------------------------------------

## ğŸš€ Overview

This project is an interactive **video transcription and annotation
tool** designed for research workflows such as:

-   Interview speech transcription and analysis
-   Qualitative coding & thematic analysis

It combines **Whisper** for transcription and **GPT** for assistive
labeling in a clean Gradio web interface.

------------------------------------------------------------------------

## âœ¨ Key Features

### ğŸ”Š Whisper Transcription

-   Supports Whisper models: `tiny`, `base`, `small`, `medium`, `large`
-   Model hotâ€‘swapping via dropdown
-   Automatic punctuation normalization

### ğŸ§© Segment Editing

-   Clickâ€‘toâ€‘edit transcript segments
-   Merge segments (`3,4,5` or `3â€‘5`)
-   Split segments by **pasting text to split after**
-   Automatic `segment_id` reindexing

### ğŸ· Manual Labeling

-   Speaker
-   Turn type (Question / Answer / etc.)
-   Theme codes
-   Notes

### ğŸ¤– GPTâ€‘Assisted Suggestions

-   Suggests turn type & theme code
-   Explains reasoning
-   Now it remains advisory. Future work if needed: autoâ€‘fill dropdowns

### ğŸ’¾ Autosave & Load

-   Autosaves on transcription & label edits
-   Load sessions from JSON files

### ğŸ“¤ Export

-   `.srt` subtitle file
-   `.json` structured annotation file

------------------------------------------------------------------------

## ğŸ›  Installation

- Note: ffmpeg needs to be installed on your system.

``` bash
git clone https://github.com/yourusername/video-transcriber.git
cd video-transcriber

conda create -n video_transcriber python=3.11
conda activate video_transcriber

pip install -r requirements.txt
```
------------------------------------------------------------------------

## â–¶ï¸ Usage

``` bash
python run_transcriber.py
```

Open your browser at:

    http://127.0.0.1:7860

------------------------------------------------------------------------

## ğŸ“ Project Structure

    video-transcriber/
    â”œâ”€â”€ run_transcriber.py
    â”œâ”€â”€ utils_core.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ UserData/
        â”œâ”€â”€ my_api_key.txt (â€¼ï¸Not included in the repository. You have to create one with GPT api key inside by yourself.)
        â””â”€â”€ Saved/
            â””â”€â”€saved_segments.json

------------------------------------------------------------------------

## ğŸ“Œ Notes

-   Designed for qualitative research workflows
-   Fully manual + AIâ€‘assisted hybrid coding
-   Safe autosave prevents annotation loss

------------------------------------------------------------------------

## ğŸ™ Acknowledgments

- Whisper (OpenAI)
- Gradio
- OpenAI GPT APIs
- Contributions from HCI research workflows

------------------------------------------------------------------------


## ğŸ“ License

MIT License
